{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOaqG7-s9Kb0",
    "outputId": "95e0e807-5221-4fad-d64e-d0a026271382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7_-teoww9L1z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import download\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6BQJSsiYEGL",
    "outputId": "735ce915-4394-45e5-d91d-4cba2c95eea4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/content/drive/My Drive/dataset/yelp_2013.csv',encoding='utf8', engine='python', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fH0Cyw3OYwQi"
   },
   "outputs": [],
   "source": [
    "df = df.sample(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "odr1EnX4CpaT",
    "outputId": "f4ee463f-72d1-4230-daa5-7413e254f815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 82290 unique words in the dataset.\n",
      "There are 30000 unique tweets in the dataset.\n"
     ]
    }
   ],
   "source": [
    "data = df['text'].map(word_tokenize).values\n",
    "total_vocabulary = set(word.lower() for review in data for word in review)  # set created from nested comprehension\n",
    "print('There are {} unique words in the dataset.'.format(len(total_vocabulary)))\n",
    "print('There are {} unique tweets in the dataset.'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nGZFkFIuYXXa"
   },
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D, CuDNNLSTM\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, optimizers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gXHaHG9_X1Lt"
   },
   "outputs": [],
   "source": [
    "# set the emotion/sentiment as our target\n",
    "target = df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "njvXMFyNYcFt"
   },
   "outputs": [],
   "source": [
    "# use one hot encoding since our target is categorical\n",
    "y = pd.get_dummies(target).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "43ybjWUwYcQu"
   },
   "outputs": [],
   "source": [
    "# use keras to create a Tokenizer object\n",
    "tokenizer = text.Tokenizer(num_words=40000)  # limit to the num_words most important ones\n",
    "tokenizer.fit_on_texts(list(df['text']))\n",
    "tokenized_texts = tokenizer.texts_to_sequences(df['text'])\n",
    "X = pad_sequences(tokenized_texts, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzQs6BfNYcaA",
    "outputId": "cc41f00a-a5b4-423c-817e-23b45f9cf950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 128)         10976384  \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, None, 256)        264192    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, None, 128)         197120    \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 50)                6450      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,446,951\n",
      "Trainable params: 11,446,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# create my NN model\n",
    "model = Sequential()\n",
    "\n",
    "embedding_size = 128\n",
    "model.add(Embedding(len(total_vocabulary), embedding_size))\n",
    "model.add(Bidirectional(CuDNNLSTM(128, return_sequences=True)))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))  # use 5 because we have 5 categories\n",
    "opt = optimizers.Adam(learning_rate=0.0025)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary() # check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCE7IanSZZdS",
    "outputId": "9269bebf-88a2-4cc2-db1b-d975acfd584e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "338/338 [==============================] - 13s 39ms/step - loss: 1.6070 - accuracy: 0.2211 - val_loss: 1.6031 - val_accuracy: 0.2134\n",
      "Epoch 2/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 1.6095 - accuracy: 0.2030 - val_loss: 1.5624 - val_accuracy: 0.3183\n",
      "Epoch 3/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 1.5824 - accuracy: 0.2400 - val_loss: 1.5591 - val_accuracy: 0.2313\n",
      "Epoch 4/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 1.5763 - accuracy: 0.2500 - val_loss: 1.5718 - val_accuracy: 0.2363\n",
      "Epoch 5/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 1.5556 - accuracy: 0.2728 - val_loss: 1.5265 - val_accuracy: 0.3021\n",
      "Epoch 6/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 1.3112 - accuracy: 0.3823 - val_loss: 1.2099 - val_accuracy: 0.4517\n",
      "Epoch 7/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 1.1261 - accuracy: 0.4604 - val_loss: 1.1414 - val_accuracy: 0.4644\n",
      "Epoch 8/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 1.0078 - accuracy: 0.5168 - val_loss: 1.1254 - val_accuracy: 0.4871\n",
      "Epoch 9/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.9125 - accuracy: 0.5792 - val_loss: 1.0013 - val_accuracy: 0.5112\n",
      "Epoch 10/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.8098 - accuracy: 0.6389 - val_loss: 1.0995 - val_accuracy: 0.5273\n",
      "Epoch 11/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.6823 - accuracy: 0.6492 - val_loss: 1.0318 - val_accuracy: 0.5516\n",
      "Epoch 12/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.6712 - accuracy: 0.6515 - val_loss: 0.9431 - val_accuracy: 0.5731\n",
      "Epoch 13/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.6672 - accuracy: 0.6694 - val_loss: 0.9845 - val_accuracy: 0.6026\n",
      "Epoch 14/20\n",
      "338/338 [==============================] - 13s 38ms/step - loss: 0.6855 - accuracy: 0.6885 - val_loss: 0.8589 - val_accuracy: 0.6131\n",
      "Epoch 15/20\n",
      "338/338 [==============================] - 13s 38ms/step - loss: 0.7144 - accuracy: 0.6939 - val_loss: 0.8361 - val_accuracy: 0.6125\n",
      "Epoch 16/20\n",
      "338/338 [==============================] - 13s 38ms/step - loss: 0.6971 - accuracy: 0.6936 - val_loss: 0.8715 - val_accuracy: 0.5971\n",
      "Epoch 17/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.6933 - accuracy: 0.7080 - val_loss: 0.8261 - val_accuracy: 0.5923\n",
      "Epoch 18/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.6923 - accuracy: 0.7234 - val_loss: 0.7947 - val_accuracy: 0.5731\n",
      "Epoch 19/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.6951 - accuracy: 0.7019 - val_loss: 0.7842 - val_accuracy: 0.6122\n",
      "Epoch 20/20\n",
      "338/338 [==============================] - 13s 37ms/step - loss: 0.6812 - accuracy: 0.7034 - val_loss: 0.7847 - val_accuracy: 0.5981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f395c13f1f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjZ49rNYZbEW",
    "outputId": "0082fdb5-d378-4771-e4ed-a35467927000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 2s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "y_pred = model.predict(X_test) # get our predictions\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayAVMLRXeGbx",
    "outputId": "7a8c9a03-5933-4e65-d5d6-84d35349ca57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6038"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
